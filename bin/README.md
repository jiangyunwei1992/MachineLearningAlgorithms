1. 损失函数：度量预测的错误程度，是f(X)和Y的非负实值函数，记做L(Y,f(x))，损失函数值越小，模型越好
   常用损失函数:
   1) 0-1损失函数：L(Y,f(X)) = Y==f(X)? 0 : 1
   2) 平方损失函数：L(Y,f(X)) = (Y-f(X))^2
   3) 绝对损失函数：L(Y,f(X)) = |Y-f(x)|
   4) 对数损失函数：L(Y,f(X)) = -logP(Y|X)
   期望风险 = ∫L(y,f(x))P(x,y)dxdy
   经验风险 = ΣL(yi,f(xi))/N
   
2. 过拟合：一味追求提高对训练数据的预测能力，所选模型的复杂度往往比真模型更高，这种现象称为过拟合。学习时，
   选择的模型包含过多参数，以致于对已知数据预测的很好，但对未知数据预测很差
   
3. 选择模型的两种方法：
   1) 正则化：在经验风险上加一个正则化项和罚项。符合奥卡姆剃刀原理：在所有可能选择的模型中，能够很好地解释
   已知数据而且十分简单才是最好的模型，也就是最应该选择的模型。
   2) 交叉验证：将样本随机分成三个部分：
   训练集：训练模型
   验证集：选择模型
   测试集：对最终学习方法进行评估
   一般由于样本有限，将数据切分为训练集和测试集，反复训练、测试以及模型选择
   a) 简单交叉验证：将已知数据随机分成训练集和测试集，使用训练集在各种条件下训练模型，从而得到不同的模型；
      在测试集上评价各个模型的测试误差，选出测试误差最小的模型
   b) S折交叉验证（最常用）：随机将已知数据切分成S个互不相交的大小相同的子集，利用S-1个子集的数据训练模型，
      剩下的子集测试模型。选择S次评测中，平均测试误差最小的模型
  
 4. 泛化能力：训练的模型对未知数据的预测能力
 
 5. 生成模型：Generative Model，对给定的输入预测相应的输出。根据数据学习联合概率分布P(X,Y)，然后求出
    条件概率分布P(Y|X)作为预测模型
    P(Y|X) = P(X,Y)/P(X)
    常见：朴素贝叶斯、隐马尔科夫模型
    特点：直接学习条件概率P(Y|X)或者决策函数f(X)，直接面对预测，往往准确率更高
    
 6. 判别模型：Discriminative Model，根据数据直接学习决策函数f(x)或者条件概率分布P(Y|X)作为预测的模型
 	常见：KNN，感知机，决策树，逻辑斯谛回归，最大熵模型，支持向量机，提升方法，条件随机场等
 	特点：生成方法可以还原出联合概率分布P(X,Y)，判别方法则不能；生成方法收敛速度更快，当存在隐变量时，
 	仍然可以用生成方法学习，此时不能使用判别方法
 	
 7. 准确率 = TP/(TP+FP)
 	召回率 = TP/(TP+FN)
 	F1 = 2TP/(2TP+FP+FN)